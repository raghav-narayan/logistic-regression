{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGC Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdd64ca-03ae-4f4d-a7a0-ca8574e1c548"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61add02-d176-466f-c378-3f59a9ec4013"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512f1eec-f06d-4286-eba7-795669c89573"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938ae964-476a-417d-db80-192502abe4e0"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.10 seconds.\n",
            "Convergence after 10 epochs took 0.10 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7f8524-0497-4f78-8989-eb80c8554ac9"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4zia9GqgqY7"
      },
      "source": [
        "def logloss(y,y_score):\n",
        "  \"\"\"Defining the loss function for single component \n",
        "given a y and y_score values\"\"\"\n",
        "  term1 = y*math.log(y_score,10)\n",
        "  term2 = (1-y)*math.log(1-y_score,10)\n",
        "  return term1+term2"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    x=np.arange(len(dim))\n",
        "    w=np.zeros_like(x,shape=len(dim))\n",
        "    b=0\n",
        "\n",
        "    return w,b"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdc5173-811a-4245-91e9-e93570e0eb4b"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fcbffd-68c3-416b-d6e1-653e8cd224f7"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c15a7e-e226-4178-aaf0-6bf400ac42c4"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    loss=0.0\n",
        "    for i in range(len(y_true)):\n",
        "      loss+=(y_true[i])*np.log10(y_pred[i])+(1-y_true[i])*np.log10(1-y_pred[i])\n",
        "    loss/=len(y_true)\n",
        "    return -loss"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e289f649-1000-4b64-f4a2-c9825bda966d"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw=x*((y)-sigmoid(np.dot(w,x)+b))-((alpha*w)/N)\n",
        "    return dw"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f76cfe-8b74-4e6a-de27-370820528e92"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        "def gradient_db(x,y,w,b):\n",
        "  '''In this function, we will compute gradient w.r.to b '''\n",
        "  db = y-sigmoid(np.dot(w,x)+b)\n",
        "  return db"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d88205-548f-4255-ee88-d4cc83ca96e3"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    train_loss=[]\n",
        "    test_loss=[]\n",
        "    \n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    w,b = initialize_weights(X_train[0])\n",
        "    for i in tqdm(range(epochs)):\n",
        "      for j in range(len(X_train)):\n",
        "        dw = gradient_dw(X_train[j],y_train[j],w,b,alpha,1)\n",
        "        db = gradient_db(X_train[j],y_train[j],w,b)\n",
        "        w = w + (eta0*dw)\n",
        "        b = b + (eta0*db)\n",
        "      \n",
        "      y_pred_train = prob_pred(w,b,X_train)\n",
        "      loss1 = logloss(y_train,y_pred_train)\n",
        "      train_loss.append(loss1)\n",
        "\n",
        "      y_pred_test = prob_pred(w,b,X_test)\n",
        "      loss2 = logloss(y_test,y_pred_test)\n",
        "      test_loss.append(loss2)\n",
        "      \n",
        "    # for every epoch\n",
        "        # for every data point(X_train,y_train)\n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "           #update w, b\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the train loss values in a list\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        # store all the test loss values in a list\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
        "\n",
        "    return w,b,train_loss,test_loss"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c910366-b129-4527-fb80-c0f38b24cdf7"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=100\n",
        "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [02:31<00:00,  1.52s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44134036-72e9-4359-991a-fc862d37e268"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.00616992,  0.00745289,  0.00028932, -0.00355709, -0.01288104,\n",
              "          0.00942305,  0.00741869,  0.00423166,  0.01244023, -0.00717488,\n",
              "          0.00157051, -0.00481057, -0.00166376,  0.00038662,  0.00033594]]),\n",
              " array([-0.03895337]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a670fa28-3062-4ecd-b933-f18b1a14e236"
      },
      "source": [
        "epoch = [i+1 for i in range(100)]\n",
        "plt.plot(epoch,test_loss,label='Test Loss')\n",
        "plt.plot(epoch,train_loss,label='Train Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Log loss')\n",
        "plt.title('Log loss of train and test vs number of epochs')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f90fc9e-89dc-4f57-fdcc-8dc727da2450"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9521866666666666\n",
            "0.94992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k28U1xDsLIO"
      },
      "source": [
        "def prob_pred(w,b,X):\n",
        "  N=len(X)\n",
        "  predict=[]\n",
        "  for i in range(N):\n",
        "    z=np.dot(w,X[i])+b\n",
        "    predict.append(sigmoid(z))\n",
        "  return predict"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMokBfs3-2PY"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}